{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare\n",
    "import wrangle\n",
    "import explore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler, MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, RFE \n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train, Validate, Test Data Frames Cleaned (Outliers Removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43332, 19), (18572, 19), (15476, 19))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean Data with Outliers Removed\n",
    "train, validate, test = wrangle.clean_zillow(wrangle.get_zillow_data()) \n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rawcensustractandblock</th>\n",
       "      <th>roomcnt</th>\n",
       "      <th>unitcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "      <th>logerror</th>\n",
       "      <th>heatingorsystemdesc</th>\n",
       "      <th>propertylandusedesc</th>\n",
       "      <th>county</th>\n",
       "      <th>age</th>\n",
       "      <th>taxrate</th>\n",
       "      <th>acres</th>\n",
       "      <th>structure_dollar_per_sqft</th>\n",
       "      <th>land_dollar_per_sqft</th>\n",
       "      <th>bed_bath_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14505</th>\n",
       "      <td>1</td>\n",
       "      <td>936</td>\n",
       "      <td>34.07</td>\n",
       "      <td>-117.76</td>\n",
       "      <td>60374023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>60,374,023,033,004.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>Floor/Wall</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>93</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.48</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bathroomcnt  calculatedfinishedsquarefeet             latitude  \\\n",
       "14505            1                           936                34.07   \n",
       "\n",
       "                 longitude  rawcensustractandblock  roomcnt  unitcnt  \\\n",
       "14505              -117.76                60374023        0        1   \n",
       "\n",
       "       assessmentyear   censustractandblock             logerror  \\\n",
       "14505            2016 60,374,023,033,004.00                -0.04   \n",
       "\n",
       "      heatingorsystemdesc        propertylandusedesc       county  age  \\\n",
       "14505          Floor/Wall  Single Family Residential  Los Angeles   93   \n",
       "\n",
       "                   taxrate                acres  structure_dollar_per_sqft  \\\n",
       "14505                 0.02                 0.09                       9.48   \n",
       "\n",
       "       land_dollar_per_sqft       bed_bath_ratio  \n",
       "14505                  2.55                 2.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set option to see all colums in dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43332 entries, 14505 to 54422\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   bathroomcnt                   43332 non-null  int64  \n",
      " 1   calculatedfinishedsquarefeet  43332 non-null  int64  \n",
      " 2   latitude                      43332 non-null  float64\n",
      " 3   longitude                     43332 non-null  float64\n",
      " 4   rawcensustractandblock        43332 non-null  int64  \n",
      " 5   roomcnt                       43332 non-null  int64  \n",
      " 6   unitcnt                       43332 non-null  int64  \n",
      " 7   assessmentyear                43332 non-null  int64  \n",
      " 8   censustractandblock           43332 non-null  float64\n",
      " 9   logerror                      43332 non-null  float64\n",
      " 10  heatingorsystemdesc           43332 non-null  object \n",
      " 11  propertylandusedesc           43332 non-null  object \n",
      " 12  county                        43332 non-null  object \n",
      " 13  age                           43332 non-null  int64  \n",
      " 14  taxrate                       43332 non-null  float64\n",
      " 15  acres                         43332 non-null  float64\n",
      " 16  structure_dollar_per_sqft     43332 non-null  float64\n",
      " 17  land_dollar_per_sqft          43332 non-null  float64\n",
      " 18  bed_bath_ratio                43005 non-null  float64\n",
      "dtypes: float64(9), int64(7), object(3)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split and Scale Data for Clustering and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_county(row):\n",
    "    if row['fips'] == 6037:\n",
    "        return 'Los Angeles'\n",
    "    elif row['fips'] == 6059:\n",
    "        return 'Orange'\n",
    "    elif row['fips'] == 6111:\n",
    "        return 'Ventura'\n",
    "    \n",
    "###########################################################\n",
    "\n",
    "def create_features(df):\n",
    "    df['age'] = 2017 - df.yearbuilt\n",
    "    # create taxrate variable\n",
    "    df['taxrate'] = df.taxamount/df.taxvaluedollarcnt\n",
    "    # create acres variable\n",
    "    df['acres'] = df.lotsizesquarefeet/43560\n",
    "    # dollar per square foot-structure\n",
    "    df['structure_dollar_per_sqft'] = df.structuretaxvaluedollarcnt/df.calculatedfinishedsquarefeet\n",
    "    # dollar per square foot-land\n",
    "    df['land_dollar_per_sqft'] = df.landtaxvaluedollarcnt/df.lotsizesquarefeet\n",
    "    # ratio of beds to baths\n",
    "    df['bed_bath_ratio'] = df.bedroomcnt/df.bathroomcnt\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def remove_outliers(df):\n",
    "    '''\n",
    "    remove outliers in bed, bath, zip, square feet, acres & tax rate\n",
    "    '''\n",
    "    df[((train.bathroomcnt <= 7) & (df.bedroomcnt <= 7) & \n",
    "               (df.regionidzip < 100000) & \n",
    "               (df.bathroomcnt > 0) & \n",
    "               (df.bedroomcnt > 0) & \n",
    "               (df.acres < 10) &\n",
    "               (df.calculatedfinishedsquarefeet < 7000) & \n",
    "               (df.taxrate < .05)\n",
    "              )]\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def col_to_drop_post_feature_creation(df):\n",
    "    cols_to_drop = ['bedroomcnt', 'taxamount', \n",
    "               'taxvaluedollarcnt', 'structuretaxvaluedollarcnt',\n",
    "               'landtaxvaluedollarcnt','lotsizesquarefeet', \"regionidzip\", \"yearbuilt\"]\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def cat_columns(df):\n",
    "    cols = [\"heatingorsystemdesc\",\"propertylandusedesc\",\"county\"]\n",
    "    df[cols] = df[cols].astype(\"category\")\n",
    "    return df \n",
    "\n",
    "###########################################################\n",
    "\n",
    "def modify_columns(df):\n",
    "    '''\n",
    "    This function drops colums that are duplicated or unneessary, creates new features, and changes column labels\n",
    "    '''\n",
    "    df['county'] = df.apply(lambda row: label_county(row), axis=1)\n",
    "    df.drop(columns = ['id','pid','id.1',\"propertylandusetypeid\", \"heatingorsystemtypeid\",'fips',\"propertyzoningdesc\",\"calculatedbathnbr\"], inplace = True)\n",
    "    df.heatingorsystemdesc = df.heatingorsystemdesc.fillna(\"None\")\n",
    "    df.latitude = df.latitude / 1000000\n",
    "    df.longitude = df.longitude / 1000000\n",
    "    #df = processing(df)  # must move after NaN have beeb addressed\n",
    "    df = create_features(df)\n",
    "    df = remove_outliers(df)\n",
    "    df = col_to_drop_post_feature_creation(df)\n",
    "    df = cat_columns(df)\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def split(df, target_var):\n",
    "    # split df into train_validate (80%) and test (20%)\n",
    "    train_validate, test = train_test_split(df, test_size=.20, random_state=13)\n",
    "    # split train_validate into train(70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=13)\n",
    "    \n",
    "def label_county(row):\n",
    "    if row['fips'] == 6037:\n",
    "        return 'Los Angeles'\n",
    "    elif row['fips'] == 6059:\n",
    "        return 'Orange'\n",
    "    elif row['fips'] == 6111:\n",
    "        return 'Ventura'\n",
    "    \n",
    "###########################################################\n",
    "\n",
    "def create_features(df):\n",
    "    df['age'] = 2017 - df.yearbuilt\n",
    "    # create taxrate variable\n",
    "    df['taxrate'] = df.taxamount/df.taxvaluedollarcnt\n",
    "    # create acres variable\n",
    "    df['acres'] = df.lotsizesquarefeet/43560\n",
    "    # dollar per square foot-structure\n",
    "    df['structure_dollar_per_sqft'] = df.structuretaxvaluedollarcnt/df.calculatedfinishedsquarefeet\n",
    "    # dollar per square foot-land\n",
    "    df['land_dollar_per_sqft'] = df.landtaxvaluedollarcnt/df.lotsizesquarefeet\n",
    "    # ratio of beds to baths\n",
    "    df['bed_bath_ratio'] = df.bedroomcnt/df.bathroomcnt\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def remove_outliers(df):\n",
    "    '''\n",
    "    remove outliers in bed, bath, zip, square feet, acres & tax rate\n",
    "    '''\n",
    "    df[((train.bathroomcnt <= 7) & (df.bedroomcnt <= 7) & \n",
    "               (df.regionidzip < 100000) & \n",
    "               (df.bathroomcnt > 0) & \n",
    "               (df.bedroomcnt > 0) & \n",
    "               (df.acres < 10) &\n",
    "               (df.calculatedfinishedsquarefeet < 7000) & \n",
    "               (df.taxrate < .05)\n",
    "              )]\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def col_to_drop_post_feature_creation(df):\n",
    "    cols_to_drop = ['bedroomcnt', 'taxamount', \n",
    "               'taxvaluedollarcnt', 'structuretaxvaluedollarcnt',\n",
    "               'landtaxvaluedollarcnt','lotsizesquarefeet', \"regionidzip\", \"yearbuilt\"]\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def modify_columns(df):\n",
    "    '''\n",
    "    This function drops colums that are duplicated or unneessary, creates new features, and changes column labels\n",
    "    '''\n",
    "    df['county'] = df.apply(lambda row: label_county(row), axis=1)\n",
    "    df.drop(columns = ['id','pid','id.1',\"propertylandusetypeid\", \"heatingorsystemtypeid\",'fips',\"propertyzoningdesc\",\"calculatedbathnbr\"], inplace = True)\n",
    "    df.heatingorsystemdesc = df.heatingorsystemdesc.fillna(\"None\")\n",
    "    df.latitude = df.latitude / 1000000\n",
    "    df.longitude = df.longitude / 1000000\n",
    "    df = create_features(df)\n",
    "    df = remove_outliers(df)\n",
    "    df = col_to_drop_post_feature_creation(df)\n",
    "    return df\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def split(df):\n",
    "    # split df into train_validate (80%) and test (20%)\n",
    "    train_validate, test = train_test_split(df, test_size=.20, random_state=13)\n",
    "    # split train_validate into train(70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=13)\n",
    "    return train, validate, test \n",
    "    \n",
    "###########################################################\n",
    "\n",
    "def clean_data(train, validate, test):\n",
    "    # Continuous valued columns to use median to replace nulls\n",
    "    cols = [\n",
    "        \"structuretaxvaluedollarcnt\",\n",
    "        \"taxamount\",\n",
    "        \"taxvaluedollarcnt\",\n",
    "        \"landtaxvaluedollarcnt\",\n",
    "        \"structuretaxvaluedollarcnt\",\n",
    "        \"finishedsquarefeet12\",\n",
    "        \"calculatedfinishedsquarefeet\",\n",
    "        \"fullbathcnt\",\n",
    "        \"lotsizesquarefeet\",\n",
    "        \"unitcnt\",\n",
    "        \"regionidcity\",\n",
    "        \"buildingqualitytypeid\",\n",
    "        \"regionidcity\",\n",
    "        \"regionidzip\",\n",
    "        \"yearbuilt\",\n",
    "        \"censustractandblock\"\n",
    "    ]\n",
    "    for col in cols:\n",
    "        median = train[col].median()\n",
    "        train[col].fillna(median, inplace=True)\n",
    "        validate[col].fillna(median, inplace=True)\n",
    "        test[col].fillna(median, inplace=True)\n",
    "    return train, validate, test\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def processing(train, validate, test):\n",
    "    \n",
    "    cols = [\"yearbuilt\",\"calculatedfinishedsquarefeet\",\"regionidzip\",\n",
    "            \"bathroomcnt\",\"bedroomcnt\",\"lotsizesquarefeet\",\"rawcensustractandblock\",\n",
    "            \"roomcnt\",\"unitcnt\",\"assessmentyear\"]\n",
    "    train[cols] = train[cols].astype('int')\n",
    "    validate[cols] = validate[cols].astype('int')\n",
    "    test[cols] = test[cols].astype('int')\n",
    "    return train, validate, test     \n",
    "\n",
    "###########################################################\n",
    "\n",
    "def remove_columns(train, validate, test, cols_to_remove):  \n",
    "    train = train.drop(columns=cols_to_remove)\n",
    "    validate = validate.drop(columns=cols_to_remove)\n",
    "    test = test.drop(columns=cols_to_remove)\n",
    "    return train, validate, test\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def handle_missing_values(train, validate, test, prop_required_column = .5, prop_required_row = .75):\n",
    "    threshold = int(round(prop_required_column*len(train.index),0))\n",
    "    train.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_column*len(validate.index),0))\n",
    "    validate.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_column*len(test.index),0))\n",
    "    test.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "\n",
    "    threshold = int(round(prop_required_row*len(train.columns),0))\n",
    "    train.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_row*len(validate.columns),0))\n",
    "    validate.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_row*len(test.columns),0))\n",
    "    test.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    return train, validate, test\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def x_train(train, validate, test, target_var):\n",
    "    # create X_train by dropping the target variable \n",
    "    X_train = train.drop(columns=[target_var])\n",
    "    # create y_train by keeping only the target variable.\n",
    "    y_train = train[[target_var]]\n",
    "\n",
    "    # create X_validate by dropping the target variable \n",
    "    X_validate = validate.drop(columns=[target_var])\n",
    "    # create y_validate by keeping only the target variable.\n",
    "    y_validate = validate[[target_var]]\n",
    "\n",
    "    # create X_test by dropping the target variable \n",
    "    X_test = test.drop(columns=[target_var])\n",
    "    # create y_test by keeping only the target variable.\n",
    "    y_test = test[[target_var]]\n",
    "    \n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def col_to_drop_post_processing(train, validate, test):\n",
    "    cols_to_drop = ['bedroomcnt', 'taxamount', \n",
    "               'taxvaluedollarcnt', 'structuretaxvaluedollarcnt',\n",
    "               'landtaxvaluedollarcnt', 'yearbuilt', \n",
    "               'lotsizesquarefeet','regionidzip']\n",
    "    train = train.drop(columns = cols_to_drop)\n",
    "    validate = validate.drop(columns = cols_to_drop)\n",
    "    test = test.drop(columns = cols_to_drop)\n",
    "    return train, validate, test\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def clean_zillow(df):\n",
    "    modify_columns(df)\n",
    "    train, validate, test = split(df)\n",
    "    train, validate, test = clean_data(train, validate, test)\n",
    "    train, validate, test = remove_columns(train, validate, test, cols_to_remove=['buildingqualitytypeid','finishedsquarefeet12','fullbathcnt', 'regionidcounty',\"regionidcity\",'tdate', 'parcelid', 'propertycountylandusecode'])\n",
    "    train, validate, test = handle_missing_values(train, validate, test)\n",
    "    train, validate, test = processing(train, validate, test) \n",
    "    train, validate, test = col_to_drop_post_processing(train, validate, test)\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = x_train(train, validate, test, 'logerror')\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test  \n",
    "\n",
    "###########################################################\n",
    "\n",
    "def cat_columns(X_train, X_validate, X_test):\n",
    "    cols = [\"heatingorsystemdesc\",\"propertylandusedesc\",\"county\"]\n",
    "    X_train[cols] = X_train[cols].astype(\"category\")\n",
    "    X_validate[cols] = X_validate[cols].astype(\"category\")\n",
    "    X_test[cols] = X_test[cols].astype(\"category\")\n",
    "    return X_train, X_validate, X_test \n",
    "\n",
    "###########################################################\n",
    "\n",
    "def scale_min_max(X_train, X_validate, X_test):\n",
    "    # create the scaler object and fit to X_train (get the min and max from X_train for each column)\n",
    "    scaler = MinMaxScaler(copy=True, feature_range=(0,1)).fit(X_train)\n",
    "\n",
    "    # transform X_train values to their scaled equivalent and create df of the scaled features\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), \n",
    "                                  columns=X_train.columns.values).set_index([X_train.index.values])\n",
    "    \n",
    "    # transform X_validate values to their scaled equivalent and create df of the scaled features\n",
    "    X_validate_scaled = pd.DataFrame(scaler.transform(X_validate),\n",
    "                                    columns=X_validate.columns.values).set_index([X_validate.index.values])\n",
    "\n",
    "    # transform X_test values to their scaled equivalent and create df of the scaled features   \n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), \n",
    "                                 columns=X_test.columns.values).set_index([X_test.index.values])\n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def model_zillow(X_train, X_validate, X_test):\n",
    "    X_train, X_validate, X_test = cat_columns(X_train, X_validate, X_test)\n",
    "    X_train_scaled, X_validate_scaled, X_test_scaled = scale_min_max(X_train, X_validate, X_test)\n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat_columns() missing 2 required positional arguments: 'X_validate' and 'X_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-662dd6614adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mclean_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1b2f81c82dd7>\u001b[0m in \u001b[0;36mclean_zillow\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mmodify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1b2f81c82dd7>\u001b[0m in \u001b[0;36mmodify_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_to_drop_post_feature_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cat_columns() missing 2 required positional arguments: 'X_validate' and 'X_test'"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test  = clean_zillow(df)\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled = model_zillow(X_train, X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Create New Features**  (def create_features(df))\n",
    "\n",
    "\n",
    "age: 2017 - year built   \n",
    "\n",
    "\n",
    "tax_rate: taxamount/taxvaluedollarcnt fields (total, land & structure). We can then remove taxamount and \n",
    "          taxvaluedollarcnt, and will keep taxrate, structuretaxvaluedollarcnt, and landtaxvalue\n",
    "          \n",
    "          \n",
    "acres: lotsizesquarefeet/43560   \n",
    "\n",
    "\n",
    "\n",
    "structure_dollar_per_sqft: structure tax value/finished square feet  \n",
    "\n",
    "\n",
    "land_dollar_per_sqft: land tax value/lot size square feet\n",
    "\n",
    "\n",
    "bed_bath_ratio: bedroomcnt/bathroomcnt   \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Remove Outliers** (remove_outliers())\n",
    "\n",
    "1. remove extremes in bedrooms and baths, we will keeps homes with between 1 and 7 baths, between 0 and 7 \n",
    "    bedrooms\n",
    "\n",
    "2. there is an error in zip, so we will remove those whose zips are invalid numbers (> 99999).\n",
    "\n",
    "3. remove square feet > 7000 for now\n",
    "\n",
    "4. remove lot size (acres) > 10 for now\n",
    "\n",
    "5. remove tax rate > 5% for now.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Drop Columns**\n",
    "\n",
    "- For now, I will focus on the most difficult and diverse county, LA county. I'll add the others in after I see what I can find.\n",
    "\n",
    "- I'm not sure where I will use bins and where I will use actual values, so for now I think i'll go with bins and see what happens.\n",
    "\n",
    "- I will remove the following variables:\n",
    "\n",
    "    parcelid: can tie back to parcels later\n",
    "\n",
    "    bedroomcnt: info captured in bed_bath_ratio + bathroomcnt\n",
    "\n",
    "    taxamount, taxvaluedollarcnt, structuretaxvaluedollarcnt, landtaxvaluedollarcnt: info captured in tax_bin + \n",
    "    structure_dollar_per_sqft + land_dollar_per_sqft + acres + calculatedfinishedsquarefeet\n",
    "\n",
    "    yearbuilt: info captured in age\n",
    "\n",
    "    lotsizesquarefeet: info captured in acres\n",
    "\n",
    "    regionidcity: using boolean of whether in city of LA or not\n",
    "\n",
    "    regionidzip: not using at this time\n",
    "\n",
    "    LA, Orange, Ventura: will look at LA county only right now.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validate, test = remove_outliers(train, validate, test)\n",
    "# train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert categorical to cat.codes (Outliers)\n",
    "# train_c, validate_c, test_c = wrangle.catcode_zillow(train, validate, test)\n",
    "# # Scale train (Outliers)\n",
    "# X_train_scaled, X_validate_scaled, X_test_scaled = wrangle.scale_df(train_c, validate_c, test_c)\n",
    "# X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Train (Target Variable = Log Error) W/Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train_scaled[['age', 'bmi', 'children', 'smoker', 'charges']]\n",
    "# kmeans = KMeans(n_clusters=5)\n",
    "# kmeans.fit(X)\n",
    "# train['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Visualizations (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How bedroomcount affects the relationship between squarefeet and logerror\n",
    "\n",
    "# sns.scatterplot(x='calculatedfinishedsquarefeet', y='logerror',\n",
    "#                data=train)\n",
    "# plt.title(\"Visualizing the relationship between logerror and squarefeet\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How tax value affects logerror\n",
    "\n",
    "# sns.scatterplot(x='taxvaluedollarcnt', y='logerror',\n",
    "#                data=train)\n",
    "# plt.title(\"Visualizing the relationship between logerror and Assessed Tax Value\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Dataframes based on County w/ Outliers Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split in to train df per county, remove outliers using IQR (6)\n",
    "# #df = wrangle.get_zillow_data()\n",
    "# train, validate, test = wrangle.clean_zillow(wrangle.get_zillow_data()) \n",
    "# la_train_df, vc_train_df, oc_train_df = explore.counties_no_outliers(train)\n",
    "# la_train_df.shape, vc_train_df.shape, oc_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LA County\n",
    "\n",
    "# #Convert categorical to cat.codes (Outliers) - Only using Train\n",
    "# la_train_c, validate_c, test_c = wrangle.catcode_zillow(la_train_df, validate, test)\n",
    "# # Scale train (Outliers)\n",
    "# la_train_scaled = wrangle.county_scaler(la_train_c)\n",
    "# la_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ventura County\n",
    "\n",
    "# #Convert categorical to cat.codes (Outliers) - Only using Train\n",
    "# la_train_c, validate_c, test_c = wrangle.catcode_zillow(la_train_df, validate, test)\n",
    "# # Scale train (Outliers)\n",
    "# la_train_scaled = wrangle.county_scaler(la_train_c)\n",
    "# la_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def county_catcode(train):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def county_scaler(train):\n",
    "#     X_train = train\n",
    "#     # Scale data\n",
    "#     scaler = MinMaxScaler(copy=True).fit(X_train)\n",
    "#     X_train_scaled = scaler.transform(X_train)\n",
    "#     X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns.values).set_index([X_train.index.values])\n",
    "#     return X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la_train_scaled = county_scaler(la_train_c)\n",
    "# la_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orange County\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la_X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Visualizations w/Outliers Removed (Per County)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How bedroomcount affects the relationship between squarefeet and logerror (La County)\n",
    "\n",
    "# sns.scatterplot(x='calculatedfinishedsquarefeet', y='logerror',\n",
    "#                data=la_train_df)\n",
    "# plt.title(\"Visualizing the relationship between logerror and squarefeet in LA County\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How bedroomcount affects the relationship between squarefeet and logerror (Ventura County)\n",
    "\n",
    "# sns.scatterplot(x='calculatedfinishedsquarefeet', y='logerror',\n",
    "#                data=vc_train_df)\n",
    "# plt.title(\"Visualizing the relationship between logerror and squarefeet in Ventura County\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How bedroomcount affects the relationship between squarefeet and logerror (Orange County)\n",
    "\n",
    "# sns.scatterplot(x='calculatedfinishedsquarefeet', y='logerror',\n",
    "#                data=oc_train_df)\n",
    "# plt.title(\"Visualizing the relationship between logerror and squarefeet in Orange County\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How tax value affects logerror in LA County\n",
    "\n",
    "# sns.scatterplot(x='taxvaluedollarcnt', y='logerror',\n",
    "#                data=la_train_df)\n",
    "# plt.title(\"Visualizing the relationship between logerror and Assessed Tax Value in LA County\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How tax value affects logerror in Ventura County\n",
    "\n",
    "# sns.scatterplot(x='taxvaluedollarcnt', y='logerror',\n",
    "#                data=vc_train_df)\n",
    "# plt.title(\"Visualizing the relationship between logerror and Assessed Tax Value in Ventura County\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How tax value affects logerror in Orange County\n",
    "\n",
    "# sns.scatterplot(x='taxvaluedollarcnt', y='logerror',\n",
    "#                data=oc_train_df)\n",
    "# plt.title(\"Visualizing the relationship between logerror and Assessed Tax Value in Orange County\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
